{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c559bbd",
   "metadata": {},
   "source": [
    "# Питон и машинное обучение\n",
    "\n",
    "# Модуль 2. Предварительная обработка данных\n",
    "\n",
    "- Добавление, удаление, визуализация признаков\n",
    "- Нормализация и шкалирование данных\n",
    "- Преобразования признаков\n",
    "- Кодирование признаков\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from scipy import stats \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17effe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('always', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbd04d",
   "metadata": {},
   "source": [
    "### Работа с признаками в Pandas\n",
    "\n",
    "Здесь мы рассмотрим базовые операции по предобработке данных в контексте отдельных признаков датасета.\n",
    "\n",
    "Предварительный анализ признаков лучше делать на полном датасете, который включает в себя и определяющую, и результирующую части.\n",
    "\n",
    "Более подробно про модификацию признаков будет рассказано по ходу курса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# снова загрузим \"ирисы\"\n",
    "iris_raw = datasets.load_iris()\n",
    "iris = pd.DataFrame(iris_raw.data, columns=iris_raw.feature_names)\n",
    "iris['y'] = iris_raw.target\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3280e16",
   "metadata": {},
   "source": [
    "Переименование признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.columns = ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'y']\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975f4f5",
   "metadata": {},
   "source": [
    "Посмотреть статистические характеристики для всех числовых признаков можно при помощи функции ```describe()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3b964",
   "metadata": {},
   "source": [
    "Получить данные по конкретному признаку можно, обратившись к нему как к элементу словаря, это даст объект ```pd.Series``` с соответствующей колонкой из загруженной таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb483e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['sepal_l'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sepal_l # такой способ обращения тоже поддерживается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073dca4",
   "metadata": {},
   "source": [
    "Чтобы обратиться к каким-либо важным, на ваш взгляд, характеристикам датасета, можно использовать булевы маски.\n",
    "\n",
    "Например, вот так можно посмотреть все ирисы, у которых ```sepal_l``` больше медианного значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13faa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[ iris.sepal_l > iris.sepal_l.median() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8826ed1e",
   "metadata": {},
   "source": [
    "Для подсчета уникальных значений категориальных признаков удобно пользоваться функцией ```value_counts()```. \n",
    "\n",
    "Например, вот так можно узнать распределение классов для нашего среза из предыдущей клетки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec016b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[ iris.sepal_l > iris.sepal_l.median() ].y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79181ba",
   "metadata": {},
   "source": [
    "#### Визуализация признаков\n",
    "\n",
    "Матрица диаграмм рассеяния, по диагонали - гистограммы распределения значений по каждому признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.plotting.scatter_matrix(iris, \n",
    "                  figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81820520",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96942f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "_ = sns.pairplot(iris,\n",
    "             diag_kind='kde', plot_kws={'alpha': 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e9693",
   "metadata": {},
   "source": [
    "Корелляционная матрица:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ff728",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "_ = sns.heatmap(iris.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "iris.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec96f7e",
   "metadata": {},
   "source": [
    "Визуализация отдельных признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79792ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['sepal_w'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd017b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.histplot(iris['sepal_w'], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2001784",
   "metadata": {},
   "source": [
    "#### Добавление и удаление признаков\n",
    "\n",
    "Вместо пары кореллирующих признаков ```petal_l``` и ```petal_w``` сделаем новый признак ```petal_avg```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_ = iris.copy()\n",
    "\n",
    "iris_['petal_avg'] = (iris_.petal_l + iris_.petal_w) / 2\n",
    "iris_.drop(['petal_l', 'petal_w'], axis=1, inplace=True)\n",
    "iris_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.heatmap(iris_[['sepal_l','sepal_w','petal_avg','y']].corr(), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(iris_[['sepal_l','sepal_w','petal_avg','y']], diag_kind='kde', plot_kws={'alpha': 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8a368",
   "metadata": {},
   "source": [
    "## Немного теории: виды распределений вероятностей\n",
    "\n",
    "Чаще всего приходится иметь дело со следующими видами распределений:\n",
    "- __Нормальное (Гауссово)__ - идеальный случай для большинства задач, соответствует ЦПТ, и т.д.\n",
    "- __Логнормальное__ - распределение, которое приводится к нормальному после логарифмирования величин. Характерно для следующих данных:\n",
    "    - доходы физических и юридических лиц\n",
    "    - количество комментариев под постами в соц. сетях и интернет-магазинах\n",
    "    - другое...\n",
    "- __Бернулли__, __Пуассона__ - распределение вероятностей бинарной или дискретной случайной величины соответсвенно.\n",
    "- __Бета-распределение__ - используется для предсказания вероятностей, параметры ```a``` - мера успеха, ```b``` - неуспеха, в сопряжении с распределением Бернулли.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1687e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = np.random.normal(size=1000)\n",
    "data_lognorm = np.random.lognormal(size=1000)\n",
    "data_beta = pd.DataFrame({'a=0.5, b=0.5': np.random.beta(a=0.5, b=0.5, size=1000),\n",
    "                          'a=1, b=1': np.random.beta(a=1, b=1, size=1000),\n",
    "                          'a=2, b=8': np.random.beta(a=2, b=8, size=1000),\n",
    "                          'a=50, b=50': np.random.beta(a=10, b=10, size=1000),\n",
    "                         })\n",
    "\n",
    "fig, axs = plt.subplots( 1, 3 )\n",
    "fig.set_size_inches( (15, 5) )\n",
    "axs[0].set_title('Нормальное (Гауссово)')\n",
    "axs[1].set_title('Логнормальное')\n",
    "axs[2].set_title('Бета')\n",
    "\n",
    "sns.histplot(data_norm, ax=axs[0], kde=True)\n",
    "sns.histplot(data_lognorm, ax=axs[1], kde=True)\n",
    "sns.histplot(data_beta, ax=axs[2], kde=True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ba3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ec3071",
   "metadata": {},
   "source": [
    "Как понять на сколько мы близки к нормальному распределению? Как можно это измерить?\n",
    "\n",
    "Можно использовать оценки Шапиро-Уилка и Колмогорова-Смирнова. ```pvalue``` в обоих случаях - это вероятность нуль-гипотезы \"данные распрпделены нормально\". То есть чем выше значение ```pvalue```, тем ближе к нормальному распределение анализируемых данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac433cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.shapiro(data_norm))\n",
    "print()\n",
    "print(stats.shapiro(data_lognorm))\n",
    "print()\n",
    "print(stats.shapiro(data_beta['a=50, b=50'])) \n",
    "print()\n",
    "print(stats.shapiro(data_beta['a=1, b=1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71560b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.kstest(data_norm, 'norm'))\n",
    "print()\n",
    "print(stats.kstest(data_lognorm, 'norm'))\n",
    "print()\n",
    "print(stats.kstest(data_beta['a=50, b=50'], 'norm')) \n",
    "print()\n",
    "print(stats.kstest(data_beta['a=1, b=1'], 'norm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf9e43",
   "metadata": {},
   "source": [
    "‼️ ВАЖНО! Для проверки данных на \"нормальность\" тестом Колмогорова-Смирнова их нужно шкалировать (приводить к распределению с мат. ожиданием в 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c709af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print( stats.kstest(StandardScaler().fit_transform(pd.DataFrame(data_beta['a=50, b=50']))[0], 'norm') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390906d",
   "metadata": {},
   "source": [
    "#### Логнормальное распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.histplot(data_lognorm, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots( 2, 1 )\n",
    "fig.set_size_inches( (8, 8) )\n",
    "axs[0].set_title('Логнормальное')\n",
    "axs[1].set_title('После логарифмирования')\n",
    "\n",
    "sns.histplot(data_lognorm, ax=axs[0], kde=True)\n",
    "sns.histplot(np.log10(data_lognorm), ax=axs[1], kde=True)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(stats.shapiro(data_lognorm))\n",
    "print()\n",
    "print(stats.shapiro(np.log10(data_lognorm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7e9a4",
   "metadata": {},
   "source": [
    "### Мультимодальное распределение\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fce18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_1 = np.random.normal(10, 3, 1000)\n",
    "dist_2 = np.random.normal(30, 5, 4000)\n",
    "dist_3 = np.random.normal(45, 6, 800)\n",
    "\n",
    "multimodal_dist = np.concatenate((dist_1, dist_2, dist_3), axis=0)\n",
    "\n",
    "_ = sns.histplot(multimodal_dist, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f582061",
   "metadata": {},
   "source": [
    "Вычислить моды позволяет модель ```GaussianMixture```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39231fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=3)\n",
    "gmm.fit(multimodal_dist.reshape(-1, 1))\n",
    "\n",
    "means = gmm.means_.flatten()\n",
    "\n",
    "# сигмы вычисляем по квадратным корням ковариантностей\n",
    "standard_deviations = ( gmm.covariances_**0.5 ).flatten()\n",
    "\n",
    "# пропорции данных в распределениях\n",
    "weights = gmm.weights_.flatten()\n",
    "\n",
    "\n",
    "print(f\"Means: {means},\\n\\\n",
    "Standard Deviations: {standard_deviations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbb486",
   "metadata": {},
   "source": [
    "### Преобразования признаков\n",
    "\n",
    "1. Min-max шкалирование:\n",
    "\n",
    "\n",
    "$\\tilde{x}_i = \\frac{x_i - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "Позволяет поместить данные в диапазон ```[0, 1]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "iris_minmax = pd.DataFrame( MinMaxScaler().fit_transform(iris.iloc[ :, :-1 ]), columns = iris.columns[:-1] )\n",
    "iris_minmax.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e04209",
   "metadata": {},
   "source": [
    "2. Стандартное шкалирование: нормализация с мат. ожиданием в 0 и дисперсией 1:\n",
    "\n",
    "$\\tilde{x}_i = \\frac{x_i - \\mu}{\\sigma}$\n",
    "\n",
    "Не приводит данные к нормальному распределению, но позволяет \"сгладить\" выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris_std = pd.DataFrame( StandardScaler().fit_transform(iris.iloc[ :, :-1 ]), columns = iris.columns[:-1] )\n",
    "iris_std.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581ed25",
   "metadata": {},
   "source": [
    "3. L2-нормализация: каждый вектор делится на свой модуль:\n",
    "\n",
    "$\\tilde{x} = \\frac{x}{||x||}$\n",
    "\n",
    "\"Горизонтальная\" нормализация - нормализуется каждый вектор из набора данных (приводится к модулю = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887976d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "iris_norm = pd.DataFrame( normalize(iris.iloc[ :, :-1 ]), columns = iris.columns[:-1] )\n",
    "iris_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63280f",
   "metadata": {},
   "source": [
    "Построим матрицы диаграмм рассеяния и корелляции для различных способов шкалирования и нормализации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f899a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(iris_std,\n",
    "             diag_kind='kde', plot_kws={'alpha': 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.heatmap(iris.corr(), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ff7a0",
   "metadata": {},
   "source": [
    "Подробнее о различных способах нормализации можно прочитать в [официальной документации ```scikit-learn```](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676087b5",
   "metadata": {},
   "source": [
    "#### ⁉️ Задание\n",
    "\n",
    "1. В датасете \"Ирисы\" проверьте признак ```sepal_w``` на соответствие нормальному распределению.\n",
    "2. В загруженном датасете \"Ирисы\" вычислите моды распределения по признакам ```petal_l``` и ```petal_w``` и сравните их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e395c37",
   "metadata": {},
   "source": [
    "### Обработка нестандартных распределений и \"выбросов\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "biz_f = open('data/yelp_academic_dataset_business.json')\n",
    "biz_df = pd.DataFrame([json.loads(x) for x in biz_f.readlines()])\n",
    "biz_f.close()\n",
    "\n",
    "biz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3af275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.DataFrame({'review_count': biz_df['review_count']})\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots()\n",
    "df_reviews['review_count'].hist(ax=ax, bins=100)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Review Count')\n",
    "ax.set_ylabel('Occurrence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e067d",
   "metadata": {},
   "source": [
    "Выполним логарифмирование и шкалирование, посмотрим как изменилась гистограмма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(4, 1)\n",
    "\n",
    "fig.set_size_inches( (8, 12) )\n",
    "axs[0].set_title('Оригинальное распределение')\n",
    "axs[1].set_title('Шкалированное распределение')\n",
    "axs[2].set_title('Логарифмированное распределение')\n",
    "axs[3].set_title('Логарифмированное и затем шкалированное распределение')\n",
    "\n",
    "df_reviews_std = pd.DataFrame(StandardScaler().fit_transform(df_reviews), columns=df_reviews.columns) \n",
    "df_reviews_log = pd.DataFrame(np.log10(df_reviews), columns=df_reviews.columns)\n",
    "df_reviews_log_std = pd.DataFrame(StandardScaler().fit_transform(df_reviews_log), columns=df_reviews.columns) \n",
    "\n",
    "\n",
    "df_reviews['review_count'].hist(ax=axs[0], bins=100)\n",
    "df_reviews_std['review_count'].hist(ax=axs[1], bins=100)\n",
    "df_reviews_log['review_count'].hist(ax=axs[2], bins=100)\n",
    "df_reviews_log_std['review_count'].hist(ax=axs[3], bins=100)\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_yscale('log')\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b134a7",
   "metadata": {},
   "source": [
    "### Бининг🗑️, квантилизация и степенные преобразования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cef9a8",
   "metadata": {},
   "source": [
    "Бининг по заданным значениям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,500,1000,10000]\n",
    "\n",
    "labels = [f\"rw_{border}_{bins[i+1]}\" for i, border in enumerate(bins[:-1]) ]\n",
    "\n",
    "pd.get_dummies( pd.cut(df_reviews['review_count'], bins=bins, labels=labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63c517",
   "metadata": {},
   "source": [
    "Квантилизация по децилям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = df_reviews['review_count'].quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_reviews['review_count'].hist(ax=ax, bins=100)\n",
    "for pos in deciles:\n",
    "    handle = plt.axvline(pos, color='r')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Review Count')\n",
    "ax.set_ylabel('Occurrence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0327433",
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles_ = pd.concat([pd.Series([0.0]), deciles, pd.Series([1.0e5])])\n",
    "\n",
    "labels = [f\"{i+1}: {v:.0f}-{deciles_.iloc[i+1]:.0f}\" for i, (q, v) in enumerate(deciles_.iloc[:-1].items()) ]\n",
    "\n",
    "pd.get_dummies( \n",
    "    pd.cut(df_reviews['review_count'], bins=deciles_, labels=labels), \n",
    "    prefix='q', \n",
    "    dtype=np.int64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df_reviews['review_count'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.histplot(pd.qcut(df_reviews['review_count'], 10, labels=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies( \n",
    "    pd.qcut(df_reviews['review_count'], 10, labels=False), \n",
    "    prefix='q', \n",
    "    dtype=np.int64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4992d",
   "metadata": {},
   "source": [
    "Другой способ квантильных преобразований:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "\n",
    "_ = sns.histplot( qt.fit_transform(data_lognorm.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b49a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "_ = sns.histplot( qt.fit_transform(df_reviews), ax=ax, legend=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce51b36",
   "metadata": {},
   "source": [
    "Степенные преобразования, преобразование Бокса-Кокса:\n",
    "\n",
    "$y^{(\\lambda )}_i =\\begin{cases}\\frac{y^\\lambda_i-1}{\\lambda}&\\lambda \\neq 0\\cr \\ln(y) &\\lambda =0\\end{cases}.$\n",
    "\n",
    "и Йео-Джонсона:\n",
    "\n",
    "$y^{(\\lambda )}_i =\\begin{cases}[{(y_i + 1)^\\lambda-1}]/{\\lambda} &\\lambda \\neq 0, y_i \\geq 0 \\cr\\\n",
    "\\ln(y)&\\lambda = 0, y_i \\geq 0 \\cr\\\n",
    "-[(-y_i + 1)^{(2-\\lambda)} - 1]/(2 - \\lambda) &\\lambda \\neq 2, y_i < 0 \\cr\\\n",
    "-\\ln(-y_i+1）&\\lambda = 2, y_i < 0\n",
    "\\end{cases}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be869efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "# pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "_ = sns.histplot( pt.fit_transform(data_lognorm.reshape(-1, 1)), legend=None )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_cox_transformer = pt.fit(df_reviews)\n",
    "\n",
    "print(box_cox.lambdas_)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "_ = sns.histplot(box_cox_transformer.transform(df_reviews), ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721aca6",
   "metadata": {},
   "source": [
    "#### ⁉️ Задание\n",
    "\n",
    "Загрузите датасет ```data/credit_scoring.csv``` и проанализируйте признак ```Income```:\n",
    "\n",
    "1. Избавьтесь от NaN, объясните почему вы выбрали тот или иной способ избавления от пропусков\n",
    "2. Приведите данные в Income к нормальному распределению. Пришлите статистику и pvalue сравнения Income с нормальным распределением по Шапиро-Уилка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e389742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/credit_scoring.csv', index_col='client_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6facb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24c69d",
   "metadata": {},
   "source": [
    "## Кодирование признаков\n",
    "\n",
    "Многие алгоритмы машинного обучения не могут работать с текстовой информацией.\n",
    "\n",
    "Такая информация может быть либо переведена в dummy-признаки, либо закодирована.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad999e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv('data/bank.csv')\n",
    "bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154e3f1",
   "metadata": {},
   "source": [
    "Рассмотрим на примере признаков ```job``` и ```education```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank.job.value_counts())\n",
    "print(bank.education.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460d2f4",
   "metadata": {},
   "source": [
    "Чтобы не сильно увеличивать размерность данных, предлагается признаки с небольшим количеством значений перевести в one-hot encoding и dummy-признаки, а признаки с большим количеством - закодировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8624796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "bank['job_encoded'] = enc.fit_transform(bank.job.values.reshape(-1,1))\n",
    "\n",
    "bank.job_encoded.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu = pd.get_dummies( bank.education, dtype=np.int64, prefix='education' )\n",
    "df_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb86340",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.join(df_edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaea38f",
   "metadata": {},
   "source": [
    "Можно закодировать весь датасет, но лучше сделать это только для текстовых признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40795637",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = bank.columns[ bank.dtypes == 'object']\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "a = enc.fit_transform(bank[ text_features ])\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем из него dataframe:\n",
    "df_encoded = pd.DataFrame(a, columns=text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b093da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим данные\n",
    "df_encoded.job.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59caf2e",
   "metadata": {},
   "source": [
    "Также в ```sklearn``` реализован one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95739701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "enc.fit(bank[ text_features ])\n",
    "\n",
    "a = enc.transform(bank[ text_features ]).toarray()\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как вернуть названия признаков?\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81226d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i, text_feature in enumerate(text_features):\n",
    "    for value in enc.categories_[i]:\n",
    "        columns += [f\"{text_feature}_{value}\"]\n",
    "df_one_hot = pd.DataFrame(a, columns=columns)\n",
    "df_one_hot   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e7fe0e",
   "metadata": {},
   "source": [
    "#### ⁉️ Задание\n",
    "\n",
    "Для данного датасета ```bank.csv``` выполните следующее:\n",
    "\n",
    "1. Закодируйте бинарные признаки в 0 и 1 (1=истина).\n",
    "1. Закодируйте те признаки, в которых не более четырех значений методом one-hot.\n",
    "2. Закодируйте названия месяцев в числа 1-12 в соответствии месяцу.\n",
    "3. Все остальные текстовые признаки закодируйте методом OrdinalEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
