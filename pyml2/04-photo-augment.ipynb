{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python и машинное обучение: нейронные сети и компьютерное зрение\n",
    "\n",
    "## Модуль 4. Классификация фото и Аугментация данных\n",
    "\n",
    "- Загрузка и организация датасета для классификации\n",
    "- Создание сверточной нейронной сети \"с ноля\"\n",
    "- Раширение набора данных с помощью аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VZasS5YznmFD",
    "outputId": "378b9f85-6146-4c0a-9628-a4c3dda39417"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy, AUROC\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1Uh-p26DEdK",
    "outputId": "66d1b529-bbcb-4eb5-b30c-f9e8e592d489"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \\\n",
    "    \"mps\" if torch.backends.mps.is_built() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnBfYjNYnmFK"
   },
   "source": [
    "## Датасет\n",
    "\n",
    "Будет использоваться набор данных cats vs. dogs:\n",
    "`https://www.kaggle.com/c/dogs-vs-cats/data`.\n",
    "\n",
    "Он состоит из изображений среднего размера, в формате JPEG, примерно таких:\n",
    "\n",
    "![cats_vs_dogs_samples](https://s3.amazonaws.com/book.keras.io/img/ch5/cats_vs_dogs_samples.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AmogMvCziSf",
    "outputId": "ab698bbb-6f0b-4197-93d7-0aca04992cc5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBB12R8VTN3M"
   },
   "source": [
    "Копируем файлы в runtime (иначе обучение будет идти ооочень медленно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDKlsaWxbn9p"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/datasets/cats_and_dogs_small /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QetsJj7ozrrC",
    "outputId": "54f11ab1-72f5-43a0-97df-cbed34cc6db3"
   },
   "outputs": [],
   "source": [
    "!ls -al /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R16BzBOB2ILp"
   },
   "source": [
    "Датасет уже разбит на обучающую, валидационную и тестовую выборки. Тестовая выборка нами использоваться не будет. Ниже создаем необходимые переменные и убеждаемся, что все файлы на местах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ccxy3jjRnmFL"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "base_dir = '/home/ise/Documents/datasets/cats_and_dogs_small'\n",
    "# base_dir = '/content/data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0lKv7TGnmFM",
    "outputId": "e4f45563-3070-4b80-de2f-b4d93eea918e"
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=150\n",
    "IMAGE_HEIGHT=150\n",
    "\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "# простой трансформинг:\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=IMAGE_SIZE), # делаем все картинки квадратными\n",
    "    transforms.ToTensor(), # преобразуем в тензор \n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transforms, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "val_data = datasets.ImageFolder(root=validation_dir, transform=data_transforms)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{val_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kHvq5sMnmFN",
    "outputId": "91f4182d-44b5-4c33-fcd9-84f57a8c1de6"
   },
   "outputs": [],
   "source": [
    "# названия классов\n",
    "class_names = train_data.classes\n",
    "print(\"Class names: \",class_names)\n",
    "\n",
    "# ...в виде словаря\n",
    "class_dict = train_data.class_to_idx\n",
    "print(\"Class names as a dict: \",class_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwcdj9tBnmFN",
    "outputId": "e79b5da9-667d-43d7-da86-aa3b64834b0b"
   },
   "outputs": [],
   "source": [
    "ix_random_image = np.random.choice(len(train_data))\n",
    "\n",
    "img, label = train_data[ix_random_image]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}={class_names[label]}\")\n",
    "display(transforms.ToPILImage()(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем генераторы и разделяем загрузку данных на несколько ядер нашего/наших CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8_MabGEnmFN",
    "outputId": "ffdf5260-a405-46ce-91a1-824dd8a10f3c"
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = os.cpu_count()\n",
    "print(f'Cores: {NUM_WORKERS}')\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "train_gen = DataLoader(dataset=train_data, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              shuffle=True) \n",
    "\n",
    "val_gen = DataLoader(dataset=val_data, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             num_workers=NUM_WORKERS, \n",
    "                             shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализируем батч\n",
    "images, labels = next(iter(train_gen))\n",
    "images_np = images.numpy()\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.transpose(images_np[idx], (1,2,0)))\n",
    "    ax.set_title(class_names[labels[idx].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJD_X_7cnmFO"
   },
   "source": [
    "## Строим нейросеть\n",
    "\n",
    "Делаем ее как композицию 4-х слоев ```Conv2D``` и ```MaxPooling2D```, емкость карт признаков - 32, 64, 128, 128. Перед выходом добавляем два полносвязных ```Dense``` слоя. В качестве функции активации выбираем (конечно) ```relu```, в последнем слое функцию активаци не делаем.\n",
    "\n",
    "Такая сеть использовалась Ф. Шолле в его книге про фреймворк Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6vyopdnnmFP"
   },
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, # принимает трехканальное изображение 3, 150, 150\n",
    "                     out_channels=32, # отдает карту признаков на 32 канала: 32, 148, 148 \n",
    "                     kernel_size=3, # ядро размера 3х3\n",
    "                     padding=0, \n",
    "                     bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)) # отдает карту признаков на 32 канала: 32, 74, 74\n",
    "            \n",
    "        # ваш код здесь\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= ? , out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = ImageClassifier().to(device)\n",
    "print(model)\n",
    "\n",
    "summary(model,\n",
    "        input_size=images.shape,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        device=device\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем функцию потерь ```crossentropy```, оптимизатор - ```RMSprop```, метрика - точность (```accuracy```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "y_preds = model(images.to(device))\n",
    "print(y_preds)\n",
    "print(labels.to(device))\n",
    "\n",
    "loss = criterion(y_preds, labels.to(device))\n",
    "print(\"Loss\", loss.data.item())\n",
    "\n",
    "print(\"Acccuracy\", (y_preds.argmax(dim=1) == labels.to(device)).float().mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batches(model,\n",
    "                  train_generator,\n",
    "                  valid_generator,\n",
    "                  batch_size=20, epochs=40, report_positions=20, **kwargs):\n",
    "\n",
    "    results = {'epoch_count': [], 'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    # прогоняем данные по нейросети\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss = valid_loss = 0.0;\n",
    "        train_correct = valid_correct = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_generator:\n",
    "\n",
    "            X_batch = X_batch.to(device); y_batch = y_batch.to(device)\n",
    "\n",
    "            y_preds = model(X_batch) \n",
    "            loss = criterion(y_preds, y_batch) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.data.item()\n",
    "            train_correct += (y_preds.argmax(dim=1) == y_batch).float().sum()\n",
    "\n",
    "        train_loss /= len(train_generator.dataset)\n",
    "        train_acc = 100 * train_correct / len(train_generator.dataset)    \n",
    "\n",
    "        # Валидацию тоже делаем по батчам\n",
    "        model.eval()\n",
    "\n",
    "        for valid_batches, (X_val_batch, y_val_batch) in enumerate(valid_generator):\n",
    "            X_val_batch = X_val_batch.to(device); y_val_batch = y_val_batch.to(device)\n",
    "            y_batch_preds = model(X_val_batch)\n",
    "            loss = criterion(y_batch_preds, y_val_batch)\n",
    "\n",
    "            valid_loss += loss.data.item()\n",
    "            valid_correct += (y_batch_preds.argmax(dim=1) == y_val_batch).float().sum()\n",
    "\n",
    "        valid_loss /= len(valid_generator.dataset)\n",
    "        valid_acc = 100 * valid_correct / len(valid_generator.dataset)\n",
    "\n",
    "        results['epoch_count'] += [epoch]\n",
    "        results['train_loss'] += [ train_loss ]\n",
    "        results['train_acc'] += [ float(train_acc) ]\n",
    "        results['val_loss'] += [ valid_loss ]\n",
    "        results['val_acc'] += [ float(valid_acc) ]\n",
    "\n",
    "        if epoch % (epochs // report_positions) == 0 or epochs<50:\n",
    "            print(f\"Epoch: {epoch+1:4.0f} | Train Loss: {train_loss:.5f}, \"+\\\n",
    "                  f\"Accuracy: {train_acc:.2f}% | \\\n",
    "            Validation Loss: {valid_loss:.5f}, Accuracy: {valid_acc:.2f}%\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# рисовалка графиков\n",
    "def plot_results(results):\n",
    "\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "\n",
    "    fig.set_size_inches(10,3)\n",
    "\n",
    "    for i, loss_acc in enumerate(['loss', 'acc']):\n",
    "        for train_val in ['train', 'val']:\n",
    "            axs[i].plot(results['epoch_count'], results[f'{train_val}_{loss_acc}'], label=f'{loss_acc} {train_val}')\n",
    "\n",
    "        axs[i].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-4)\n",
    "\n",
    "results = train_batches(model,\n",
    "                        train_gen,\n",
    "                        val_gen, epochs=30, )\n",
    "\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_r8tdtBnmFS"
   },
   "source": [
    "Очевидно переобучение: показатели на обучающей выборке гораздо лучше, чем на контрольной. Что делать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwe1eq2inmFT"
   },
   "source": [
    "## Используем data augmentation\n",
    "\n",
    "Переобучение вызвано ограниченным набором образцов - для модели явно мало 2000 картинок. Что поможет нам расширить обучающий набор? Если мы применим к каждой картинке некое преобразование (например, будем ее \"зеркалить\" по горизонтали) - это уже увеличит объем выборки вдвое. Можно также применять другие преобразования, которые оставят картинку узнаваемой человеком (глядя на нее любой сможет сказать: \"смотрите, это кот!\"), но при этом сделают ее \"новой\" для нейросети. Например, можно картинку немного увеличивать, слегка поворачивать, чуть-чуть сдвигать.\n",
    "\n",
    "Такие преобразования называют \"аугментацией данных\" - расширением обучающего набора на базе имеющегося, таким образом, что сохраняется принадлежность образцов к исходным классам.\n",
    "\n",
    "Вот пример таких преобразований:\n",
    "- вращаем в пределах 40*\n",
    "- сдвигаем по ширине на 20%\n",
    "- сдвигаем по высоте на 20%\n",
    "- делаем трапецевидный сдвиг на 20%\n",
    "- увеличиваем на 20%\n",
    "- делаем горизонтальное зеркалирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzWyrhntnmFU"
   },
   "source": [
    "Создадим новую нейросеть: у нее такая же архитектура как у предыдущей, но мы после комбинации ```Conv2D-MaxPooling2D``` добавили еще слой - прореживатель (```Dropout```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDTPGNsAnmFV"
   },
   "outputs": [],
   "source": [
    "# ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuAkA1DVcG2p"
   },
   "source": [
    "Запустим обучение: увеличим количество эпох до 100, все остальные параметры оставим как прежде. Обучение в Google Colab может занять около часа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NABqYs_NxQB8",
    "outputId": "a39d7648-e2d0-40ec-94d6-8e0d39264f86"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
